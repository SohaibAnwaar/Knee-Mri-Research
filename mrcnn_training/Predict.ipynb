{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "import mrcnn.model as modellib\n",
    "import glob\n",
    "from predict_utils import predict\n",
    "# Set CPU as available physical device\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "Mention Same Config file here as you mentioned in training notebook\n",
    "\n",
    "'''\n",
    "\n",
    "from mrcnn.config import Config\n",
    "\n",
    "class GenericConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classes, steps):\n",
    "        self.NUM_CLASSES = classes +1\n",
    "        self.STEPS_PER_EPOCH = steps\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    NAME = \"class\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.1\n",
    "    IMAGE_MAX_DIM=448\n",
    "    IMAGE_MIN_DIM=384\n",
    "    TRAIN_ROIS_PER_IMAGE=20\n",
    "    DETECTION_NMS_THRESHOLD=0.1\n",
    "    DETECTION_MAX_INSTANCES=10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Model Path Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        10\n",
      "DETECTION_MIN_CONFIDENCE       0.1\n",
      "DETECTION_NMS_THRESHOLD        0.1\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  448\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  384\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [448 448   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           class\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           20\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:From /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Re-starting from epoch 126\n",
      "Weights loaded\n",
      "771\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "weights_path = \"/media/sohaib/additional_/maskrcnn/weights/class20210901T1509/mask_rcnn_class_0126.h5\"\n",
    "MODEL_DIR = \"/\".join(weights_path.split(\"/\")[:-2])\n",
    "config = GenericConfig(2,100)\n",
    "config.display()\n",
    "\n",
    "# Create model in inference mode\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,config=config)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)  \n",
    "print(\"Weights loaded\")\n",
    "    \n",
    "\n",
    "images = [file for file in glob.glob(\"/media/sohaib/additional_/DataScience/Upwork_orders/Helm_and_zebracross/imp_projects/zebra_crossing/videos/save_images/*.*g\")]\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Training Images Path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person walking on Zebra Crossing 0.7306911945343018\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "labels = [ \"zebracrossing\", \"person\"]\n",
    "\n",
    "\n",
    "count_ = 0\n",
    "base_path = \"/media/sohaib/additional_/DataScience/Upwork_orders/Helm_and_zebracross/imp_projects/zebra_crossing/videos/predictions/\"\n",
    "for image in images:\n",
    "    \n",
    "    st = time.time()\n",
    "    out, r, count = predict(model, image, labels, 0.90)\n",
    "    \n",
    "    image_name = image.rsplit(\"/\",1)[1]\n",
    "    Image.fromarray(out).save(f\"{base_path}/{image_name}\")\n",
    "    \n",
    "#     plt.imshow(out)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    if count > 3:\n",
    "        count_ += 1\n",
    "    else:\n",
    "        count_ = 0\n",
    "    \n",
    "    \n",
    "    if count_ > 3:\n",
    "        \n",
    "        string = \"Person Not walking on Zebra Crossing\"\n",
    "    else:\n",
    "        string = \"Person walking on Zebra Crossing\"\n",
    "        \n",
    "        \n",
    "    print(string + f\" {time.time()-st}\", end = '\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
